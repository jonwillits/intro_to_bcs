# Lab 10: Connectionism and Neural Networks

## 1. Symbolic vs. Connectionist perspective (11 PTS TOTAL)

### 1.1. What are three things that make the connectionist and symbolic perspectives different? (3 PTS)

### 1.2. Comparing behaviorism to the symbolic and connectionist perspectives. 
- What are two ways that behaviorism is similar to, and two ways it is different from, the symbolic perspective (4 PTS)
- What are two ways that behaviorism is similar to, and two ways it is different from, the connnectionist perspective? (4 PTS)

# 2. Connectionist Rock-Paper-Scissors
Previously, you played a symbolic AI that played rock-paper-scissors.
Now, answer the following questions about how the program would have to be different to be implemented as a connectionist program.

## 2.1. Next-move Prediction (12 PTS TOTAL)
Imagine a neural network that was trying to predict what your next move was going to be.
What would the model need to be like? 

- 2.1.1. What information would need to be represented in the input and output layers? (2 PTS)
- 2.1.2. Would the network need a "hidden" layer? Why or why not? (2 PTS)
- 2.1.3. Would the network need a "recurrent" layer? Why would one help? Is there a way you can represent the problem without one? (3 PTS)
- 2.1.4. Describe how a "Hebbian Learning" vs. an "Error Driven Learning" version of this model would be different. (2 PTS)
- 2.1.5. Would such a prediction model need to be good at winning rock-paper-scissors? Why or why not? If not, what would you need to add (3 PTS)

## 2.2. Reinforcement Learning (12 PTS TOTAL)
Now imagine a model that is trying to predict the correct next move to take.
What would that model need to be like? Answer the same five questions as above.
- 2.2.1. What information would need to be represented in the input and output layers? (2 PTS)
- 2.2.2. Would the network need a "hidden" layer? Why or why not? (2 PTS)
- 2.2.3. Would the network need a "recurrent" layer? Why would one help? Is there a way you can represent the problem without one? (3 PTS)
- 2.2.4. Describe how a "Hebbian Learning" vs. an "Error Driven Learning" version of this model would be different. (2 PTS)
- 2.2.5 Would such a reinforcement learning model need to be good at winning rock-paper-scissors? Why or why not? If not, what would you need to add (3 PTS)

## 2.3. Comparison to symbolic model.
What are 2 ways in which these neural network models would be similar to, and different from, the symbolic model we used last week.

# 3. Shape Classifier Lab
Questions available Thursday.
